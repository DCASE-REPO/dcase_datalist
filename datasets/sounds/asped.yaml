# === DATASET ===
dataset:
  name: Audio Sensing for Pedestrian Detection Dataset
  provider:
  abbreviation: ASPED
  year: 2024
  modalities: Audio, Video
  collection_name: ASPED dataset
  domain: Weak annotation
  related_datasets:

  license: Creative Commons, CC BY-NC 4.0

  download:
    url: https://urbanaudiosensing.github.io/ASPED
    size: 580GB

  companion_site: https://urbanaudiosensing.github.io/ASPED

  citation:
    ref: https://urbanaudiosensing.github.io/publications/2024_ICASSP_ASPED.pdf;Seshadri2024
    title: "ASPED: AN AUDIO DATASET FOR DETECTING PEDESTRIANS"

# === AUDIO ===
audio:
  data:
    type: Audio
    file_format:
      type: Constant
      format: flac
      lossy_compression: No
      bit_rate: 16
      sampling_rate_khz: 44.1

    channels:
      setup: Mono
      number: 1

    material:
      source: Original

  content:
    type: Freefield                     # [list], content type, possible values: Freefield | Synthetic | Isolated
    scene: Constant                     # [string], is the scene class constant for single recording, possible values: Constant | Variable

    event:
      spatial_location: Constant        # [string], possible values: Constant | Moving | Unknown

  recording:
    setup: Mixed                        # [string], possible values: Near-field | Far-field | Mixed | Uncontrolled | Unknown
    setup_count:                        # [int], amount of different recording setups (microphone and recording device) used
    spot_type: Fixed                    # [string], possible values: Fixed | Moving | Unknown

  files:
    total_count: 75
    total_duration_minutes: 156000
    file_length: Variable
    file_length_seconds:

# === META ===
meta:
  types: Event

  scene:
    classes: 1                          # [int], Number of scene classes
    class_balance: Yes                  # [string], possible values: Yes | No | Almost

  event:
    classes: 1
    class_balance: No
    list:
      - pedestrian_count

    annotation:
      type: Strong
      source: Automatic
      annotations_per_item: 1
      labelled_amount_percentage: 100
      strong_amount_percentage: 100
      overlapping_event_instances: No

    labeling:
      hierarchical: No

    instance:
      count:
      average_instances_per_class:

# === CROSS-VALIDATION SETUP ===
split:
  provided: No

# === BASELINE SYSTEM ===
baseline:
  url: https://github.com/urbanaudiosensing/Models
