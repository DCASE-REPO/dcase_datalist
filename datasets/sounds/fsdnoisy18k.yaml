# === DATASET ===
dataset:
  name: FSDnoisy18k
  provider: UPF
  abbreviation: FSDnoisy18k
  year: 2019
  modalities: Audio
  collection_name: FSD
  domain: Tagging, Weak annotation, Noisy labels
  related_datasets:                     # [list], related datasets (name or abbreviation)

  license: Creative Commons

  download:
    url: https://zenodo.org/record/2529934
    size: 9.5GB

  companion_site: http://www.eduardofonseca.net/FSDnoisy18k/

  citation:
    ref: https://arxiv.org/abs/1901.01189;Fonseca2019
    title: "Learning Sound Event Classifiers from Web Audio with Noisy Labels"

# === AUDIO ===
audio:
  data:
    type: Audio
    file_format:
      type: Constant
      format: wav
      lossy_compression:                # [bool], is audio compressed in a lossy manner, possible values: Yes | No
      bit_rate:                         # [number], Bit depth of audio, possible values: 8 | 16 | 24 | 32
      sampling_rate_khz:                # [float], Sampling rate in KHz, possible values: 8 | 16 | 22.05 | 32 | 44.1 | 48

    channels:
      setup:                            # [string], possible values: Mono | Stereo | Binaural | Ambisonic | Array | Multi-Channel | Variable
      number:                           # [int], Number of channels

    material:
      source:                           # [string or list], possible values: Original | Youtube | Freesound | Online | Crowdsourced | [Dataset name]
      variability_sources:              # [list]

  content:
    type:                               # [string], content type, possible values: Freefield | Synthetic | Isolated
    scene:                              # [string], is the scene class constant for single recording, possible values: Constant | Variable

    event:
      spatial_location:                 # [string], possible values: Constant | Moving | Unknown

    synthetic:
      event_instance_count:             # [int], amount of unique sound event instances used in synthetic mixture generation

  recording:
    setup:                              # [string], possible values: Near-field | Far-field | Mixed | Uncontrolled | Unknown
    setup_count:                        # [int], amount of different recording setups (microphone and recording device) used
    spot_type:                          # [string], possible values: Fixed | Moving | Unknown

  files:
    total_count: 18533
    total_duration_minutes: 2550
    file_length: Variable
    file_length_seconds:                # [string], Approximate length of files, can use also 4-10 notation

# === META ===
meta:
  types: Tag
  scene:
    classes:                            # [int], Number of scene classes
    class_balance:                      # [string], possible values: Yes | No | Almost
    list:                               # [list], list of scene classes

  event:
    classes: 20
    class_balance:                      # [string], possible values: Yes | No | Almost

    annotation:
      type: Weak
      source: Crowdsourced
      annotations_per_item: 1
      labelled_amount_percentage: 100
      validated_amount_percentage: 14.671127179
      strong_amount_percentage: 0
      overlapping_event_instances: Yes

    labeling:
      hierarchical: Yes
      ontology_name: AudioSet

    instance:
      count: 18533
      average_instaces_per_class: 926.65

# === CROSS-VALIDATION SETUP ===
split:
  provided: Yes
  folds: 1
  sets: Train, Test

# === BASELINE SYSTEM ===
baseline:
  url: https://github.com/edufonseca/icassp19
  cite: https://arxiv.org/abs/1901.01189;Fonseca2019
