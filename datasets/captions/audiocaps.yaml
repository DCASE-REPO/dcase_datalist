# === DATASET ===
dataset:
  name: "AudioCaps: Generating Captions for Audios in The Wild"
  provider: SNU
  abbreviation: AudioCaps                        # [string], Official dataset abbreviation, e.g. one used in the original paper
  year: 2019                                # [int], Release year
  modalities: Audio, Video
  collection_name: AudioCaps                     # [string], common name for all related datasets, used to group datasets coming from same source
  domain: Captioning, Tagging
  related_datasets:                     # [list], related datasets (name or abbreviation)
    - AudioSet

  license:                              # [string], possible values: Creative Commons | Free | Non-commercial | Commercial | Proprietary | R&D only
                                        # In case of Creative commons license, one can add licence type too, e.g., "Creative Commons, CC BY-SA 3.0"

  download:
    url: https://github.com/cdjkim/audiocaps
    size:                               # [string], Approximate package size (unit GB, MB)

  companion_site:                       # [url], Link to the companion site for the dataset, in case of single source, use data_url-field

  citation:
    ref: https://www.aclweb.org/anthology/N19-1011/;Kim2019
    title: "AudioCaps: Generating Captions for Audios in The Wild"

# === AUDIO ===
audio:
  data:
    type: Audio
    file_format:
      type:                             # [string], possible values: Constant | Variable
      format:                           # [string], Audio file format, possible value: wav | aiff | flac | mp3 | aac | ogg
      lossy_compression:                # [bool], is audio compressed in a lossy manner, possible values: Yes | No
      bit_rate:                         # [number], Bit depth of audio, possible values: 8 | 16 | 24 | 32
      sampling_rate_khz:                # [float], Sampling rate in KHz, possible values: 8 | 16 | 22.05 | 32 | 44.1 | 48

    channels:
      setup: Mono
      number: 1

    material:
      source: AudioSet
      variability_sources:              # [list]

  content:
    type: Freefield
    scene:                              # [string], is the scene class constant for single recording, possible values: Constant | Variable

    synthetic:
      event_instance_count:             # [int], amount of unique sound event instances used in synthetic mixture generation

  recording:
    setup: Unknown
    setup_count:                        # [int], amount of different recording setups (microphone and recording device) used
    spot_type: Unknown

  files:
    total_count: 51308
    total_duration_minutes: 8551.333333333
    file_length: Constant
    file_length_seconds: 10

# === META ===
meta:
  types: Caption

  scene:
    classes:                            # [int], Number of scene classes
    class_balance:                      # [string], possible values: Yes | No | Almost
    list:


  event:
    classes:                            # [int], Number of event classes
    class_balance:                      # [string], possible values: Yes | No | Almost

  caption:
    annotation:
      languages: English
      source: Crowdsourced
      captions_per_item: 1-5
      validated_amount_percentage: 100
      guidance: Word hints

    annotator_count: 108
    count: 57189

# === CROSS-VALIDATION SETUP ===
split:
  provided: Yes
  folds: 1
  sets: Train, Val, Test

# === BASELINE SYSTEM ===
baseline:
  url: https://github.com/cdjkim/audiocaps/tree/master/code
  cite:                                 # [url];[key], Paper to cite for the baseline

# === INFO ===
info:
  evaluation_campaign:                  # [string or list], if string use a comma separated list, Evaluation campaign where used e.g. DCASE2016 task1, DCASE2018 task4, CLEAR 2016, etc.
  comments:                             # [string], comments
